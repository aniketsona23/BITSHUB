{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: openai in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\divyam gupta\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\divyam gupta\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\divyam gupta\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\divyam gupta\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\divyam gupta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\divyam gupta\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and stored embeddings and text chunks for C:\\Users\\Divyam Gupta\\Desktop\\AI\\CS F213 Handout_1 2024 25 (23 files merged).pdf\n",
      "Generated Answer: Instructor in charge: Prof Neena Goveas\n",
      "Evaluative components: Lab (continuous 20%), Open Book Mid Test (25%), Closed Book Group Project (20%), Open Book End-term Exam (35%)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"OOPs RAG ChatBot.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1JwFgtgpgwu8Bb-WqDa-n11h9mVmscUN-\n",
    "\"\"\"\n",
    "\n",
    "#   PART A\n",
    "\n",
    "# Install necessary libraries\n",
    "%pip install PyPDF2 openai faiss-cpu\n",
    "%pip install --upgrade openai\n",
    "# Import necessary libraries\n",
    "import PyPDF2\n",
    "import openai\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from openai import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with your OpenAI API key\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to split text into smaller chunks\n",
    "def split_text_into_chunks(text, chunk_size=500, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Generate embeddings for text chunks\n",
    "def generate_embeddings(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        response = client.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "# Save embeddings and text chunks into a FAISS index\n",
    "def save_embeddings_to_faiss(embeddings, index_path):\n",
    "    dimension = len(embeddings[0])  # Embedding vector size\n",
    "    if os.path.exists(index_path):\n",
    "        faiss_index = faiss.read_index(index_path)\n",
    "    else:\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "        faiss_index = faiss.IndexIDMap(index)\n",
    "\n",
    "    ids = list(range(faiss_index.ntotal, faiss_index.ntotal + len(embeddings)))\n",
    "    faiss_index.add_with_ids(np.array(embeddings).astype(\"float32\"), np.array(ids))\n",
    "    faiss.write_index(faiss_index, index_path)\n",
    "\n",
    "# Process a PDF and store embeddings and chunks\n",
    "def process_pdf_and_store_embeddings(pdf_path, index_path, text_chunks_path):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    chunks = split_text_into_chunks(text)\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = generate_embeddings(chunks)\n",
    "\n",
    "    # Save embeddings and text chunks\n",
    "    save_embeddings_to_faiss(embeddings, index_path)\n",
    "    with open(text_chunks_path, \"w\", encoding=\"utf-8\") as f:  # Specify UTF-8 encoding\n",
    "        for chunk in chunks:\n",
    "            f.write(chunk + \"\\n\")\n",
    "    print(f\"Processed and stored embeddings and text chunks for {pdf_path}\")\n",
    "\n",
    "#Example Usage\n",
    "pdf_path = \"C:\\\\Users\\\\Divyam Gupta\\\\Desktop\\\\AI\\\\CS F213 Handout_1 2024 25 (23 files merged).pdf\"\n",
    "index_path = \"C:\\\\Users\\\\Divyam Gupta\\\\Desktop\\\\AI\\\\faiss_index\"\n",
    "text_chunks_path = \"C:\\\\Users\\\\Divyam Gupta\\\\Desktop\\\\AI\\\\text_chunks\"\n",
    "process_pdf_and_store_embeddings(pdf_path, index_path, text_chunks_path)\n",
    "\n",
    "# PART B\n",
    "\n",
    "\n",
    "# Load FAISS index\n",
    "def load_faiss_index(index_path):\n",
    "    return faiss.read_index(index_path)\n",
    "\n",
    "# Load text chunks from file\n",
    "def load_text_chunks(text_chunks_path):\n",
    "    with open(text_chunks_path, \"r\", encoding=\"utf-8\") as f:  # Specify UTF-8 encoding\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Generate embeddings for a query\n",
    "def generate_query_embedding(query):\n",
    "    response = client.embeddings.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    query_embedding = np.array(response.data[0].embedding).astype(\"float32\").reshape(1, -1)\n",
    "    return query_embedding\n",
    "\n",
    "# Search FAISS index for relevant chunks\n",
    "def search_faiss_index(faiss_index, query_embedding, k=5):\n",
    "    distances, indices = faiss_index.search(query_embedding, k)\n",
    "    return indices[0]  # Return indices of top-k results\n",
    "\n",
    "# Generate a response using relevant text chunks\n",
    "def generate_response(query, relevant_chunks):\n",
    "    context = \" \".join(relevant_chunks)\n",
    "    prompt = f\"Context: {context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[ {\"role\": \"system\", \"content\": \"You are a concise assistant. Provide brief and to-the-point answers.\"},\n",
    "         {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Handle query with pre-computed embeddings and text chunks\n",
    "def answer_query(query, index_path, text_chunks_path, k=5):\n",
    "    # Load stored data\n",
    "    faiss_index = load_faiss_index(index_path)\n",
    "    text_chunks = load_text_chunks(text_chunks_path)\n",
    "\n",
    "    # Generate query embedding\n",
    "    query_embedding = generate_query_embedding(query)\n",
    "\n",
    "    # Search FAISS index\n",
    "    relevant_indices = search_faiss_index(faiss_index, query_embedding, k)\n",
    "\n",
    "    # Retrieve relevant chunks\n",
    "    relevant_chunks = [text_chunks[i] for i in relevant_indices if i < len(text_chunks)]\n",
    "\n",
    "    # Generate response\n",
    "    return generate_response(query, relevant_chunks)\n",
    "\n",
    "#Example Usuage\n",
    "index_path = \"C:\\\\Users\\\\Divyam Gupta\\\\Desktop\\\\AI\\\\faiss_index\"\n",
    "text_chunks_path = \"C:\\\\Users\\\\Divyam Gupta\\\\Desktop\\\\AI\\\\text_chunks\"\n",
    "query = \"Who is the instructor in charge and what are evaluative components.\"\n",
    "answer = answer_query(query, index_path, text_chunks_path, k=5)\n",
    "print(\"Generated Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
